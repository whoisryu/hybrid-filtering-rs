{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/aryuska/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models.phrases import Phrases, Phraser\n",
    "from gensim.models import KeyedVectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbId</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>114709</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>A cowboy doll is profoundly threatened and jea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>113497</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When two kids find and play a magical board ga...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>113228</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>John and Max resolve to save their beloved bai...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>114885</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Based on Terry McMillan's novel, this film fol...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>113041</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>George Banks must deal not only with his daugh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   imdbId                        title  \\\n",
       "0  114709                    Toy Story   \n",
       "1  113497                      Jumanji   \n",
       "2  113228             Grumpier Old Men   \n",
       "3  114885            Waiting to Exhale   \n",
       "4  113041  Father of the Bride Part II   \n",
       "\n",
       "                                         description  \n",
       "0  A cowboy doll is profoundly threatened and jea...  \n",
       "1  When two kids find and play a magical board ga...  \n",
       "2  John and Max resolve to save their beloved bai...  \n",
       "3  Based on Terry McMillan's novel, this film fol...  \n",
       "4  George Banks must deal not only with his daugh...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('description.csv')\n",
    "df.head()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _removeNonAscii(s):\n",
    "    return \"\".join(i for i in s if ord(i)<128)\n",
    "\n",
    "def make_lower_case(text):\n",
    "    return text.lower()\n",
    "\n",
    "def remove_stop_words(text):\n",
    "    text = text.split()\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    text = [w for w in text if not w in stops]\n",
    "    text = \" \".join(text)\n",
    "    return text\n",
    "\n",
    "def remove_html(text):\n",
    "    html_pattern = re.compile('<.*?>')\n",
    "    return html_pattern.sub(r'', text)\n",
    "\n",
    "def remove_punctuation(text):\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    text = tokenizer.tokenize(text)\n",
    "    text = \" \".join(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['cleaned'] = df['description'].apply(_removeNonAscii)\n",
    "\n",
    "df['cleaned'] = df.cleaned.apply(func = make_lower_case)\n",
    "df['cleaned'] = df.cleaned.apply(func = remove_stop_words)\n",
    "df['cleaned'] = df.cleaned.apply(func=remove_punctuation)\n",
    "df['cleaned'] = df.cleaned.apply(func=remove_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cowboy', 'doll', 'profoundly', 'threatened', 'jealous', 'new', 'spaceman', 'action', 'figure', 'supplants', 'top', 'toy', 'boy', 's', 'bedroom']\n"
     ]
    }
   ],
   "source": [
    "#splitting the description into words\n",
    "\n",
    "corpus = []\n",
    "for words in df['cleaned']:\n",
    "    corpus.append(words.split())\n",
    "print(corpus[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62471\n"
     ]
    }
   ],
   "source": [
    "# Downloading the Google pretrained Word2Vec Model\n",
    "\n",
    "\n",
    "EMBEDDING_FILE = '/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/GoogleNews-vectors-negative300.bin.gz'\n",
    "google_word2vec = KeyedVectors.load_word2vec_format(EMBEDDING_FILE, binary=True)\n",
    "# Training our corpus with Google Pretrained Model\n",
    "\n",
    "google_model = Word2Vec(vector_size = 200, window=5, min_count = 2, workers = 1)\n",
    "\n",
    "google_model.build_vocab(corpus)\n",
    "print(google_model.corpus_count)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building TFIDF model and calculate TFIDF score\n",
    "\n",
    "tfidf = TfidfVectorizer(analyzer='word', ngram_range=(1, 3), min_df = 5, stop_words='english')\n",
    "tfidf.fit(df['cleaned'])\n",
    "\n",
    "# Getting the words from the TF-IDF model\n",
    "\n",
    "tfidf_list = dict(zip(tfidf.get_feature_names_out(), list(tfidf.idf_)))\n",
    "tfidf_feature = tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.489466224636673 [ 4.54825861e-03  3.52426409e-03 -2.30795564e-03 -1.78320764e-03\n",
      "  3.44420900e-03 -1.05015875e-03 -3.81117524e-03 -2.14770366e-03\n",
      "  3.35261831e-03  4.38879710e-03 -3.19087924e-03  1.26438681e-03\n",
      "  2.44347216e-03 -4.31742007e-03 -8.12728424e-04  3.95536702e-03\n",
      " -8.66670627e-04  3.85270896e-03 -1.78695982e-03 -3.30757978e-03\n",
      "  4.65028890e-04  4.38707473e-04 -3.51089961e-03  1.99244023e-04\n",
      "  4.48510190e-03 -1.95345885e-04  1.69617240e-03  3.86921596e-03\n",
      "  3.45246424e-03 -1.60619081e-03  1.65327906e-03  2.72157975e-03\n",
      " -1.80770096e-03  1.52847532e-03 -3.67033132e-03  3.43273766e-03\n",
      "  1.32455712e-03  2.33313325e-03 -3.10974428e-03  2.33161100e-03\n",
      "  2.72353645e-03  6.99630997e-04  2.75292405e-04 -2.40742811e-03\n",
      "  3.39290267e-03  4.68550203e-03  3.51551641e-03 -3.14511289e-03\n",
      " -4.86780424e-03 -3.67824663e-03 -3.09363124e-03 -4.97264694e-03\n",
      " -5.73499827e-04  5.17402892e-04 -1.72914029e-03 -4.05600527e-03\n",
      " -3.23346374e-03 -2.40880321e-03 -1.21137267e-03  1.86565821e-03\n",
      " -1.19193195e-04  3.18224728e-03  1.84494851e-03  2.44353944e-03\n",
      " -4.71202144e-03 -3.88843357e-03  2.23439164e-03  3.70996352e-03\n",
      "  3.75171355e-03 -9.45855980e-04  3.95669090e-03  4.17237030e-03\n",
      "  3.71175469e-03 -1.78367679e-03 -1.63531245e-03  2.59604445e-03\n",
      " -3.14890989e-03 -6.58850069e-04  1.24203379e-03 -4.12248867e-03\n",
      "  2.00980366e-03  4.93832724e-03 -2.63377675e-03  4.01314441e-03\n",
      " -6.58241508e-04  4.46503237e-03  4.48957784e-03  1.98917813e-03\n",
      " -4.06762678e-03 -6.48677360e-06  4.36847797e-04  4.58887639e-03\n",
      " -1.32589936e-04  2.16973294e-03 -2.09186901e-03 -3.42138950e-03\n",
      "  9.51048161e-04  4.36880765e-03  1.38115580e-03 -2.14760774e-03\n",
      "  4.93112905e-03  1.20148598e-03 -7.23200443e-04 -3.44318151e-03\n",
      " -4.21111053e-03  1.27497432e-03 -2.99618416e-03  3.31033836e-03\n",
      " -2.61273631e-03  1.04245183e-03 -4.71390411e-03 -4.76765400e-03\n",
      " -2.04018527e-03  3.43238120e-04  4.37414413e-03  2.25775409e-03\n",
      "  4.14447114e-03 -2.13156990e-03 -3.53438430e-03  1.78390089e-03\n",
      "  1.84488890e-04  2.97793816e-03 -1.20714784e-03 -2.41397670e-03\n",
      " -1.96420262e-03 -6.99896831e-04  3.36793368e-03 -6.02064712e-04\n",
      "  4.38982388e-03 -4.39239899e-03 -9.76133335e-04 -1.31337938e-03\n",
      "  3.79705126e-03 -2.18393747e-03 -4.58063325e-03  1.68965640e-03\n",
      " -2.77555874e-03  1.17134990e-03  1.47011282e-03 -1.19748060e-03\n",
      " -5.90010895e-04 -1.98527751e-03 -1.13704090e-03 -1.07893115e-03\n",
      " -2.08714255e-03  1.59000163e-04 -9.17048426e-04  1.80697977e-03\n",
      "  3.94392852e-03 -4.37219441e-03 -7.91776183e-05  4.01694514e-03\n",
      "  5.54203987e-04 -2.26560468e-03  2.18874819e-04  4.80898016e-04\n",
      "  4.28590458e-03  4.03810479e-03 -2.71059689e-03  2.96109449e-03\n",
      "  3.52072367e-03 -7.70122977e-04 -2.93917721e-03  3.40761780e-03\n",
      " -2.11946853e-03 -2.41455433e-04  2.70197564e-03 -4.17294959e-03\n",
      "  6.14073884e-04 -7.55512738e-04  2.05634235e-04  1.29664535e-04\n",
      "  4.09323908e-03 -2.24596146e-03 -2.71549751e-03  4.61989269e-03\n",
      " -1.37159706e-03  4.70854482e-03 -4.41549672e-03  3.76463542e-03\n",
      "  4.87310626e-03  2.29626297e-04 -2.03634915e-03 -2.86902301e-03\n",
      "  2.61207460e-03 -4.51314403e-03 -1.81411032e-03 -1.83974381e-03\n",
      " -1.69054035e-03  1.17364351e-03  1.12982211e-03 -2.86469632e-03\n",
      "  3.40932602e-04 -4.01737588e-03  4.99031134e-03  4.80127381e-03\n",
      " -2.80745863e-03  3.10498290e-03 -4.43134084e-03  2.20347755e-03]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "operands could not be broadcast together with shapes (300,) (200,) (300,) ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb Cell 8\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb#X24sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m         tf_idf \u001b[39m=\u001b[39m tfidf_list[word] \u001b[39m*\u001b[39m (desc\u001b[39m.\u001b[39mcount(word) \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(desc))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb#X24sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m         \u001b[39mprint\u001b[39m(tf_idf, vec)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb#X24sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m         sent_vec \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m (vec \u001b[39m*\u001b[39m tf_idf)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb#X24sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m         weight_sum \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m tf_idf\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb#X24sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39mif\u001b[39;00m weight_sum \u001b[39m!=\u001b[39m \u001b[39m0\u001b[39m:\n",
      "\u001b[0;31mValueError\u001b[0m: operands could not be broadcast together with shapes (300,) (200,) (300,) "
     ]
    }
   ],
   "source": [
    "# Building TF-IDF Word2Vec \n",
    "\n",
    "# Storing the TFIDF Word2Vec embeddings\n",
    "tfidf_vectors = []; \n",
    "line = 0;\n",
    "# for each book description\n",
    "for desc in corpus: \n",
    "  # Word vectors are of zero length (Used 300 dimensions)\n",
    "    sent_vec = np.zeros(300) \n",
    "    # num of words with a valid vector in the book description\n",
    "    weight_sum =0; \n",
    "    # for each word in the book description\n",
    "    for word in desc: \n",
    "        if word in google_model.wv and word in tfidf_feature:\n",
    "            vec = google_model.wv[word]\n",
    "            tf_idf = tfidf_list[word] * (desc.count(word) / len(desc))\n",
    "            print(tf_idf, vec)\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_vectors.append(sent_vec)\n",
    "    line += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6695467, 7005030)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_model.train(corpus, total_examples=google_model.corpus_count, epochs = 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the average word2vec for the each book description\n",
    "\n",
    "def vectors(x):\n",
    "    \n",
    "    # Creating a list for storing the vectors (description into vectors)\n",
    "    global word_embeddings\n",
    "    word_embeddings = []\n",
    "\n",
    "    # Reading the each movie description \n",
    "    for line in df['cleaned']:\n",
    "        avgword2vec = None\n",
    "        count = 0\n",
    "        for word in line.split():\n",
    "            if word in google_model.wv:\n",
    "                count += 1\n",
    "                if avgword2vec is None:\n",
    "                    avgword2vec = google_model.wv[word]\n",
    "                else:\n",
    "                    avgword2vec = avgword2vec + google_model.wv[word]\n",
    "                \n",
    "        if avgword2vec is not None:\n",
    "            avgword2vec = avgword2vec / count\n",
    "        \n",
    "            word_embeddings.append(avgword2vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalRecommend = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recommending the Top 5 similarmovie\n",
    "\n",
    "def recommendations(title):\n",
    "    #Check title movie\n",
    "    foundedMovie = df[df['title'] == title]\n",
    "    if foundedMovie.empty == True:\n",
    "        print(\"MOVIE NOT FOUND\")\n",
    "        return \n",
    "    \n",
    "    # Calling the function vectors\n",
    "\n",
    "    vectors(df)\n",
    "    \n",
    "    # finding cosine similarity for the vectors\n",
    "    array_embeddings = word_embeddings\n",
    "    \n",
    "    cosine_similarities = cosine_similarity(array_embeddings, array_embeddings)\n",
    "\n",
    "    movie = df[['title']]\n",
    "    #Reverse mapping of the index\n",
    "    indices = pd.Series(df.index, index = df['title']).drop_duplicates()\n",
    "         \n",
    "    idx = indices[title]\n",
    "    sim_scores = list(enumerate(cosine_similarities[idx]))\n",
    "    sim_scores = sorted(sim_scores, key = lambda x: x[1], reverse = True)\n",
    "    sim_scores = sim_scores[1:100]\n",
    "    book_indices = [i[0] for i in sim_scores]\n",
    "    recommend = movie.iloc[book_indices]\n",
    "    return recommend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>imdbid</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>cleaned</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20728</th>\n",
       "      <td>1798709</td>\n",
       "      <td>Her</td>\n",
       "      <td>In a near future, a lonely writer develops an ...</td>\n",
       "      <td>near future lonely writer develops unlikely re...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        imdbid title                                        description  \\\n",
       "20728  1798709   Her  In a near future, a lonely writer develops an ...   \n",
       "\n",
       "                                                 cleaned  \n",
       "20728  near future lonely writer develops unlikely re...  "
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "foundedMovie = df[df['title'] == 'Her']\n",
    "foundedMovie\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb Cell 13\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m recommendResult \u001b[39m=\u001b[39m recommendations(\u001b[39m\"\u001b[39;49m\u001b[39mSuperman\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n",
      "\u001b[1;32m/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb Cell 13\u001b[0m in \u001b[0;36mrecommendations\u001b[0;34m(title)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb#X14sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m idx \u001b[39m=\u001b[39m indices[title]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb#X14sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m sim_scores \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39m(\u001b[39menumerate\u001b[39m(cosine_similarities[idx]))\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb#X14sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m sim_scores \u001b[39m=\u001b[39m \u001b[39msorted\u001b[39;49m(sim_scores, key \u001b[39m=\u001b[39;49m \u001b[39mlambda\u001b[39;49;00m x: x[\u001b[39m1\u001b[39;49m], reverse \u001b[39m=\u001b[39;49m \u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb#X14sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m sim_scores \u001b[39m=\u001b[39m sim_scores[\u001b[39m1\u001b[39m:\u001b[39m100\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/aryuska/Documents/Kuliah/smt7/propo/recommendation-system/content-based.ipynb#X14sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m book_indices \u001b[39m=\u001b[39m [i[\u001b[39m0\u001b[39m] \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m sim_scores]\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "recommendResult = recommendations(\"Superman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>40068</th>\n",
       "      <td>The Right to Romance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19019</th>\n",
       "      <td>After Fall, Winter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>Go Now</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58531</th>\n",
       "      <td>Auf das Leben!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31359</th>\n",
       "      <td>The Disturbance at Dinner</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30227</th>\n",
       "      <td>American Translation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23272</th>\n",
       "      <td>Stockholm Stories</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56981</th>\n",
       "      <td>The Holiday Calendar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14357</th>\n",
       "      <td>Meng ying tong nian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35301</th>\n",
       "      <td>Ischeznuvshaya imperiya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           title\n",
       "40068       The Right to Romance\n",
       "19019         After Fall, Winter\n",
       "1782                      Go Now\n",
       "58531             Auf das Leben!\n",
       "31359  The Disturbance at Dinner\n",
       "30227       American Translation\n",
       "23272          Stockholm Stories\n",
       "56981       The Holiday Calendar\n",
       "14357        Meng ying tong nian\n",
       "35301    Ischeznuvshaya imperiya"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommendResult[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "59c1864a7ac64c421871e8212265b3774b79a935c05474e3aeca297e41ae12e2"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
